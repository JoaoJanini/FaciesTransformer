{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoaoJanini/seq2seq/blob/feature%2Fuse_proper_classes_embedding/notebooks/seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heOekHXdFLvS"
      },
      "source": [
        "## Connect to Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNPKl6i8FJes",
        "outputId": "f32786d2-49d4-4e54-f72c-7795d53322db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7ai0mx9U9Zc"
      },
      "source": [
        "## Import repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEmL3M0EkbRn",
        "outputId": "1ce1281b-beb8-4d35-c8ac-ef76103d079d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n",
            "Cloning into 'seq2seq'...\n",
            "remote: Enumerating objects: 212, done.\u001b[K\n",
            "remote: Counting objects: 100% (212/212), done.\u001b[K\n",
            "remote: Compressing objects: 100% (120/120), done.\u001b[K\n",
            "remote: Total 212 (delta 107), reused 173 (delta 73), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (212/212), 1.09 MiB | 8.40 MiB/s, done.\n",
            "Resolving deltas: 100% (107/107), done.\n"
          ]
        }
      ],
      "source": [
        "%rm -rf /content/seq2seq\n",
        "import getpass\n",
        "!git clone --branch fix/switch_to_seq_to_seq_trainer https://{getpass.getpass()}@github.com/JoaoJanini/seq2seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U1-8t1kQmMby"
      },
      "outputs": [],
      "source": [
        "!sleep 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHjmuJYhWoI5",
        "outputId": "27b27120-0072-48f8-d9e4-ef4471c0970f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/seq2seq\n"
          ]
        }
      ],
      "source": [
        "%cd seq2seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tlH_RmEXhuUm"
      },
      "outputs": [],
      "source": [
        "%mkdir data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIAA6KzFWMpq",
        "outputId": "3669c593-ad79-49d2-d80b-c64daeddb788"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.13.1+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (4.64.1)\n",
            "Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (2.9.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.3.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (2.23.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (0.0.post1)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (0.10.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (4.24.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (0.14.0)\n",
            "Requirement already satisfied: ray[tune] in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (2.1.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (2.7.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (1.7.3)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 15)) (2.5.1)\n",
            "Requirement already satisfied: tensorboard-plugin-profile in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 16)) (2.8.0)\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 17)) (1.5.1)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 18)) (0.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1->-r requirements.txt (line 1)) (4.1.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->-r requirements.txt (line 5)) (0.38.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->-r requirements.txt (line 5)) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->-r requirements.txt (line 5)) (2.14.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->-r requirements.txt (line 5)) (1.8.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->-r requirements.txt (line 5)) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->-r requirements.txt (line 5)) (1.0.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->-r requirements.txt (line 5)) (3.19.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->-r requirements.txt (line 5)) (0.4.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->-r requirements.txt (line 5)) (0.6.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->-r requirements.txt (line 5)) (1.50.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 7)) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 7)) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 7)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 7)) (3.0.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->-r requirements.txt (line 5)) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->-r requirements.txt (line 5)) (5.2.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->-r requirements.txt (line 5)) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->-r requirements.txt (line 5)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->-r requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=1.14->-r requirements.txt (line 5)) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=1.14->-r requirements.txt (line 5)) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=1.14->-r requirements.txt (line 5)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->-r requirements.txt (line 5)) (3.2.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->-r requirements.txt (line 2)) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 6)) (2022.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics->-r requirements.txt (line 9)) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 10)) (3.8.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 10)) (0.11.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 10)) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 10)) (0.13.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 10)) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics->-r requirements.txt (line 9)) (3.0.9)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from accelerate->-r requirements.txt (line 11)) (5.4.8)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 13)) (9.0.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 13)) (0.18.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 13)) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 13)) (2022.11.0)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 13)) (0.3.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 13)) (3.8.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 13)) (3.1.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r requirements.txt (line 13)) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r requirements.txt (line 13)) (22.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r requirements.txt (line 13)) (6.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r requirements.txt (line 13)) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r requirements.txt (line 13)) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r requirements.txt (line 13)) (2.1.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r requirements.txt (line 13)) (1.8.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r requirements.txt (line 13)) (0.13.0)\n",
            "Requirement already satisfied: gviz-api>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard-plugin-profile->-r requirements.txt (line 16)) (1.10.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt->-r requirements.txt (line 18)) (0.16.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt->-r requirements.txt (line 18)) (4.3.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt->-r requirements.txt (line 18)) (2.6.3)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from pymongo->hyperopt->-r requirements.txt (line 18)) (2.2.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[tune]->-r requirements.txt (line 12)) (4.3.3)\n",
            "Requirement already satisfied: click<=8.0.4,>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]->-r requirements.txt (line 12)) (7.1.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]->-r requirements.txt (line 12)) (1.0.4)\n",
            "Requirement already satisfied: virtualenv>=20.0.24 in /usr/local/lib/python3.7/dist-packages (from ray[tune]->-r requirements.txt (line 12)) (20.16.7)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[tune]->-r requirements.txt (line 12)) (0.8.10)\n",
            "Requirement already satisfied: platformdirs<3,>=2.4 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.24->ray[tune]->-r requirements.txt (line 12)) (2.5.4)\n",
            "Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.24->ray[tune]->-r requirements.txt (line 12)) (0.3.6)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]->-r requirements.txt (line 12)) (5.10.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]->-r requirements.txt (line 12)) (0.19.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGHFjYn7W-Sp"
      },
      "source": [
        "# Sequence to Sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Xvf1FcV4jC63"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "path = \"./seq2seq\"\n",
        "if path not in sys.path:\n",
        "  sys.path.append(path)\n",
        "else:\n",
        "  print(path + \"already in path\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhe1k3RvjYlO",
        "outputId": "750fc3df-d074-48df-cf52-74a6a7184d78"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content',\n",
              " '/env/python',\n",
              " '/usr/lib/python37.zip',\n",
              " '/usr/lib/python3.7',\n",
              " '/usr/lib/python3.7/lib-dynload',\n",
              " '',\n",
              " '/usr/local/lib/python3.7/dist-packages',\n",
              " '/usr/lib/python3/dist-packages',\n",
              " '/usr/local/lib/python3.7/dist-packages/IPython/extensions',\n",
              " '/root/.ipython',\n",
              " './seq2seq']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sys.path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "957DWfDKe61U"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer, logging, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "from model import FaciesForConditionalGeneration\n",
        "from configuration import FaciesConfig\n",
        "import torchmetrics\n",
        "import math\n",
        "import time\n",
        "from torch import nn, optim\n",
        "from torch.optim import Adam\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from dataset.dataset import WellsDataset\n",
        "from torch.utils.data import random_split\n",
        "from typing import List\n",
        "from datetime import datetime\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from datasets import load_dataset, load_metric\n",
        "from utils import collate_fn\n",
        "from ray.tune.schedulers import PopulationBasedTraining\n",
        "from ray.tune.search.hyperopt import HyperOptSearch\n",
        "from ray import tune\n",
        "# define function to compute metrics\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "EVAL_BATCH_SIZE = 640\n",
        "SEQUENCE_LEN = 15\n",
        "TRAINING_RATIO = 0.90\n",
        "WIRELINE_LOGS_HEADER = [\"GR\", \"NPHI\", \"RSHA\", \"DTC\", \"RHOB\", \"SP\"]\n",
        "LABEL_COLUMN_HEADER = [\"FORCE_2020_LITHOFACIES_LITHOLOGY\"]\n",
        "model_directory = f\"/content/drive/MyDrive/Coding/seq2seq/{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
        "\n",
        "train_dataset = WellsDataset(\n",
        "    dataset_type=\"train\",\n",
        "    sequence_len=SEQUENCE_LEN,\n",
        "    model_type=\"seq2seq\",\n",
        "    feature_columns=WIRELINE_LOGS_HEADER,\n",
        "    label_columns=LABEL_COLUMN_HEADER,\n",
        ")\n",
        "test_dataset = WellsDataset(\n",
        "    dataset_type=\"test\",\n",
        "    sequence_len=SEQUENCE_LEN,\n",
        "    model_type=\"seq2seq\",\n",
        "    feature_columns=WIRELINE_LOGS_HEADER,\n",
        "    label_columns=LABEL_COLUMN_HEADER,\n",
        "    scaler=train_dataset.scaler,\n",
        "    output_len=train_dataset.output_len,\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "DATA_LEN = train_dataset.train_len\n",
        "d_input = train_dataset.input_len\n",
        "d_output = train_dataset.output_len\n",
        "d_channel = train_dataset.channel_len\n",
        "tgt_vocab_size = train_dataset.output_len + len(train_dataset.special_symbols)\n",
        "TRAIN_DATA_LEN = int(DATA_LEN * TRAINING_RATIO)\n",
        "\n",
        "train_data, validation_data = random_split(\n",
        "    train_dataset, lengths=[TRAIN_DATA_LEN, DATA_LEN - TRAIN_DATA_LEN]\n",
        ")\n",
        "\n",
        "\n",
        "facies_config = {\n",
        "    \"vocab_size\": tgt_vocab_size,\n",
        "    \"max_position_embeddings\": 1024,\n",
        "    \"encoder_layers\": 6,\n",
        "    \"encoder_ffn_dim\": 1024,\n",
        "    \"encoder_attention_heads\": 8,\n",
        "    \"decoder_layers\": 4,\n",
        "    \"decoder_ffn_dim\": 1024,\n",
        "    \"decoder_attention_heads\": 8,\n",
        "    \"encoder_layerdrop\": 0.0,\n",
        "    \"decoder_layerdrop\": 0.0,\n",
        "    \"activation_function\": \"relu\",\n",
        "    \"d_model\": 512,\n",
        "    \"n_input_features\": d_input,\n",
        "    \"n_output_features\": d_output,\n",
        "    \"sequence_len\": SEQUENCE_LEN,\n",
        "    \"dropout\": 0.2,\n",
        "    \"attention_dropout\": 0.0,\n",
        "    \"activation_dropout\": 0.0,\n",
        "    \"init_std\": 0.02,\n",
        "    \"classifier_dropout\": 0.0,\n",
        "    \"scale_embedding\": False,\n",
        "    \"use_cache\": False,\n",
        "    \"num_labels\": tgt_vocab_size,\n",
        "    \"pad_token_id\": train_dataset.PAD_IDX,\n",
        "    \"bos_token_id\": train_dataset.PAD_IDX,\n",
        "    \"eos_token_id\": train_dataset.PAD_IDX,\n",
        "    \"is_encoder_decoder\": True,\n",
        "    \"decoder_start_token_id\": train_dataset.PAD_IDX,\n",
        "    \"forced_eos_token_id\": train_dataset.PAD_IDX,\n",
        "    \"return_dict\": False,\n",
        "}\n",
        "facies_transformer_config = FaciesConfig(**facies_config)\n",
        "facies_transformer_config.save_pretrained(\n",
        "    f\"{model_directory}/facies-transformer-config\"\n",
        ")\n",
        "facies_transformer_config = FaciesConfig.from_pretrained(\n",
        "    f\"{model_directory}/facies-transformer-config\"\n",
        ")\n",
        "\n",
        "\n",
        "# function to collate data samples into batch tesors\n",
        "def ray_hp_space(trial):\n",
        "    return {\n",
        "        \"learning_rate\": tune.loguniform(1e-6, 1e-4),\n",
        "        \"per_device_train_batch_size\": tune.choice([16, 32, 128, 640]),\n",
        "        \"weight_decay\": tune.uniform(0.0, 0.3),\n",
        "        \"num_train_epochs\": tune.choice([5, 10, 15]),\n",
        "        \"dropout\": tune.choice([0.3, 0.1, 0.2, 0.0, 0.4]),\n",
        "    }\n",
        "\n",
        "def compute_metrics_fn(eval_preds):\n",
        "    metrics = dict()\n",
        "    accuracy_metric = load_metric(\"accuracy\")\n",
        "    preds = eval_preds.predictions[:, 1:-1]\n",
        "    preds = preds.flatten()\n",
        "    labels = eval_preds.label_ids[:,:-2]\n",
        "    labels = labels.flatten()\n",
        "    preds = preds[labels != 0]\n",
        "    labels = labels[labels != 0]\n",
        "\n",
        "    metrics.update(accuracy_metric.compute(predictions=preds, references=labels))\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "def model_init(trial):\n",
        "    model_config = facies_transformer_config\n",
        "    if trial is not None:\n",
        "        model_config.update({\"dropout\": trial[\"dropout\"]})\n",
        "    print(\"model_init() called. updated config is\")\n",
        "    print(model_config)\n",
        "\n",
        "    return FaciesForConditionalGeneration(model_config)\n",
        "\n",
        "    return FaciesForConditionalGeneration(facies_transformer_config)\n",
        "\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=f\"{model_directory}/facies-transformer\",\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=EVAL_BATCH_SIZE,\n",
        "    disable_tqdm=True,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    num_train_epochs=10,\n",
        "    eval_steps=500,\n",
        "    generation_max_length=SEQUENCE_LEN + 2,\n",
        "    generation_num_beams=4,\n",
        "    predict_with_generate=True\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=None,\n",
        "    train_dataset=train_data,\n",
        "    data_collator=collate_fn,\n",
        "    eval_dataset=validation_data,\n",
        "    args=training_args,\n",
        "    model_init = model_init,\n",
        "    compute_metrics=compute_metrics_fn\n",
        ")\n",
        "\n",
        "best_model = trainer.hyperparameter_search(\n",
        "    direction=\"maximize\",\n",
        "    backend=\"ray\",\n",
        "    n_trials=10,\n",
        "    search_alg=HyperOptSearch(metric=\"objective\", mode=\"max\"),\n",
        "    hp_space=ray_hp_space,\n",
        "    local_dir=f\"{model_directory}/ray_results\",\n",
        "    resources_per_trial={\"gpu\": 1, \"cpu\":0}\n",
        ")\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3.8.10 ('.venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "99c6707e6b461d11f09cb1797f7e40511c3362fe9c917a4510d9e5853ba54b32"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
