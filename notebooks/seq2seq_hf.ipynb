{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heOekHXdFLvS"
      },
      "source": [
        "## Connect to Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNPKl6i8FJes",
        "outputId": "740d8ec0-66e4-4464-a0a1-57807aa47046"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7ai0mx9U9Zc"
      },
      "source": [
        "## Import repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEmL3M0EkbRn",
        "outputId": "540dc099-0eb4-40ae-94d1-92a90d59eaa2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n",
            "Cloning into 'learning'...\n",
            "remote: Enumerating objects: 223, done.\u001b[K\n",
            "remote: Counting objects: 100% (223/223), done.\u001b[K\n",
            "remote: Compressing objects: 100% (146/146), done.\u001b[K\n",
            "remote: Total 223 (delta 108), reused 170 (delta 67), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (223/223), 241.15 KiB | 6.35 MiB/s, done.\n",
            "Resolving deltas: 100% (108/108), done.\n"
          ]
        }
      ],
      "source": [
        "%rm -rf /content/learning\n",
        "import getpass\n",
        "!git clone --branch seq2seq https://{getpass.getpass()}@github.com/JoaoJanini/learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1-8t1kQmMby"
      },
      "outputs": [],
      "source": [
        "!sleep 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHjmuJYhWoI5",
        "outputId": "9c39ffc2-6270-4791-9073-1fef23585244"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/learning\n"
          ]
        }
      ],
      "source": [
        "%cd learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlH_RmEXhuUm"
      },
      "outputs": [],
      "source": [
        "%mkdir data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIAA6KzFWMpq",
        "outputId": "5b7d9eb7-e2ff-4867-f71b-7bb15f8bdb1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting torch>=1.1\n",
            "  Downloading torch-1.13.0-cp38-none-macosx_10_9_x86_64.whl (137.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 137.6 MB 30 kB/s  eta 0:00:01   |                                | 276 kB 3.5 MB/s eta 0:00:39     |██████▎                         | 26.8 MB 4.0 MB/s eta 0:00:28     |█████████▎                      | 40.0 MB 15.7 MB/s eta 0:00:07     |████████████▊                   | 54.8 MB 8.4 MB/s eta 0:00:10     |██████████████▎                 | 61.6 MB 10.2 MB/s eta 0:00:08     |████████████████████            | 86.5 MB 8.8 MB/s eta 0:00:06     |███████████████████████▏        | 99.5 MB 1.0 MB/s eta 0:00:37     |█████████████████████████████   | 125.2 MB 5.5 MB/s eta 0:00:03     |█████████████████████████████▌  | 126.9 MB 5.9 MB/s eta 0:00:02\n",
            "\u001b[?25hCollecting torchvision\n",
            "  Downloading torchvision-0.14.0-cp38-cp38-macosx_10_9_x86_64.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 3.2 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: numpy in /Users/joaojanini/Library/Python/3.8/lib/python/site-packages (from -r requirements.txt (line 3)) (1.20.3)\n",
            "Collecting tqdm\n",
            "  Using cached tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "Requirement already satisfied: tensorboard>=1.14 in /Users/joaojanini/Library/Python/3.8/lib/python/site-packages (from -r requirements.txt (line 5)) (2.7.0)\n",
            "Collecting torchtext\n",
            "  Downloading torchtext-0.14.0-cp38-cp38-macosx_10_9_x86_64.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 8.6 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: pandas in /Users/joaojanini/Library/Python/3.8/lib/python/site-packages (from -r requirements.txt (line 7)) (1.2.4)\n",
            "Requirement already satisfied: requests in /Users/joaojanini/Library/Python/3.8/lib/python/site-packages (from -r requirements.txt (line 8)) (2.26.0)\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.10.3-py3-none-any.whl (529 kB)\n",
            "\u001b[K     |████████████████████████████████| 529 kB 5.2 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 10.2 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting accelerate\n",
            "  Downloading accelerate-0.14.0-py3-none-any.whl (175 kB)\n",
            "\u001b[K     |████████████████████████████████| 175 kB 11.3 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /Users/joaojanini/Library/Python/3.8/lib/python/site-packages (from torch>=1.1->-r requirements.txt (line 1)) (4.0.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/joaojanini/Library/Python/3.8/lib/python/site-packages (from torchvision->-r requirements.txt (line 2)) (8.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /Library/Python/3.8/site-packages (from tensorboard>=1.14->-r requirements.txt (line 5)) (3.3.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /Users/joaojanini/Library/Python/3.8/lib/python/site-packages (from tensorboard>=1.14->-r requirements.txt (line 5)) (1.0.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /Users/joaojanini/Library/Python/3.8/lib/python/site-packages (from tensorboard>=1.14->-r requirements.txt (line 5)) (1.47.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/joaojanini/Library/Python/3.8/lib/python/site-packages (from tensorboard>=1.14->-r requirements.txt (line 5)) (2.3.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/joaojanini/Library/Python/3.8/lib/python/site-packages (from tensorboard>=1.14->-r requirements.txt (line 5)) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/joaojanini/Library/Python/3.8/lib/python/site-packages (from tensorboard>=1.14->-r requirements.txt (line 5)) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/site-packages (from tensorboard>=1.14->-r requirements.txt (line 5)) (41.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /Library/Python/3.8/site-packages (from tensorboard>=1.14->-r requirements.txt (line 5)) (1.0.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /Users/joaojanini/Library/Python/3.8/lib/python/site-packages (from tensorboard>=1.14->-r requirements.txt (line 5)) (3.19.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/joaojanini/Library/Python/3.8/lib/python/site-packages (from tensorboard>=1.14->-r requirements.txt (line 5)) (0.6.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/site-packages (from tensorboard>=1.14->-r requirements.txt (line 5)) (0.33.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /Library/Python/3.8/site-packages (from pandas->-r requirements.txt (line 7)) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /Users/joaojanini/Library/Python/3.8/lib/python/site-packages (from pandas->-r requirements.txt (line 7)) (2021.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Library/Python/3.8/site-packages (from requests->-r requirements.txt (line 8)) (3.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/joaojanini/Library/Python/3.8/lib/python/site-packages (from requests->-r requirements.txt (line 8)) (2.0.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/joaojanini/Library/Python/3.8/lib/python/site-packages (from requests->-r requirements.txt (line 8)) (1.26.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/joaojanini/Library/Python/3.8/lib/python/site-packages (from requests->-r requirements.txt (line 8)) (2021.5.30)\n",
            "Requirement already satisfied: packaging in /Library/Python/3.8/site-packages (from torchmetrics->-r requirements.txt (line 10)) (20.9)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Library/Python/3.8/site-packages (from transformers->-r requirements.txt (line 11)) (5.4.1)\n",
            "Collecting regex!=2019.12.17\n",
            "  Downloading regex-2022.10.31-cp38-cp38-macosx_10_9_x86_64.whl (294 kB)\n",
            "\u001b[K     |████████████████████████████████| 294 kB 7.2 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-macosx_10_11_x86_64.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 5.8 MB/s eta 0:00:01     |█████████████████████▉          | 2.6 MB 5.8 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 5.2 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: filelock in /Users/joaojanini/Library/Python/3.8/lib/python/site-packages (from transformers->-r requirements.txt (line 11)) (3.0.12)\n",
            "Requirement already satisfied: psutil in /Library/Python/3.8/site-packages (from accelerate->-r requirements.txt (line 12)) (5.8.0)\n",
            "Requirement already satisfied: six in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/site-packages (from absl-py>=0.4->tensorboard>=1.14->-r requirements.txt (line 5)) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/joaojanini/Library/Python/3.8/lib/python/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->-r requirements.txt (line 5)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/joaojanini/Library/Python/3.8/lib/python/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->-r requirements.txt (line 5)) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/joaojanini/Library/Python/3.8/lib/python/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->-r requirements.txt (line 5)) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/joaojanini/Library/Python/3.8/lib/python/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /Library/Python/3.8/site-packages (from packaging->torchmetrics->-r requirements.txt (line 10)) (2.4.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/joaojanini/Library/Python/3.8/lib/python/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=1.14->-r requirements.txt (line 5)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /Users/joaojanini/Library/Python/3.8/lib/python/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->-r requirements.txt (line 5)) (3.1.1)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2343 sha256=5ff34095a00f47ed592b896b34d0e281f5c344d200259c00606e937ee6a060c1\n",
            "  Stored in directory: /Users/joaojanini/Library/Caches/pip/wheels/14/25/f7/1cc0956978ae479e75140219088deb7a36f60459df242b1a72\n",
            "Successfully built sklearn\n",
            "Installing collected packages: tqdm, torch, tokenizers, regex, huggingface-hub, transformers, torchvision, torchtext, torchmetrics, sklearn, accelerate\n",
            "\u001b[33m  WARNING: The script tqdm is installed in '/Users/joaojanini/Library/Python/3.8/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "\u001b[33m  WARNING: The scripts convert-caffe2-to-onnx, convert-onnx-to-caffe2 and torchrun are installed in '/Users/joaojanini/Library/Python/3.8/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "\u001b[33m  WARNING: The script huggingface-cli is installed in '/Users/joaojanini/Library/Python/3.8/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "\u001b[33m  WARNING: The script transformers-cli is installed in '/Users/joaojanini/Library/Python/3.8/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "\u001b[33m  WARNING: The scripts accelerate, accelerate-config and accelerate-launch are installed in '/Users/joaojanini/Library/Python/3.8/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "Successfully installed accelerate-0.14.0 huggingface-hub-0.11.0 regex-2022.10.31 sklearn-0.0.post1 tokenizers-0.13.2 torch-1.13.0 torchmetrics-0.10.3 torchtext-0.14.0 torchvision-0.14.0 tqdm-4.64.1 transformers-4.24.0\n",
            "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 22.3.1 is available.\n",
            "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGHFjYn7W-Sp"
      },
      "source": [
        "# Sequence to Sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xvf1FcV4jC63"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "path = \"./seq2seq\"\n",
        "if path not in sys.path:\n",
        "  sys.path.append(path)\n",
        "else:\n",
        "  print(path + \"already in path\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhe1k3RvjYlO",
        "outputId": "96cbc7e0-7861-4bd7-824f-56df1fb7405b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content',\n",
              " '/env/python',\n",
              " '/usr/lib/python37.zip',\n",
              " '/usr/lib/python3.7',\n",
              " '/usr/lib/python3.7/lib-dynload',\n",
              " '',\n",
              " '/usr/local/lib/python3.7/dist-packages',\n",
              " '/usr/lib/python3/dist-packages',\n",
              " '/usr/local/lib/python3.7/dist-packages/IPython/extensions',\n",
              " '/root/.ipython',\n",
              " './seq2seq']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sys.path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "957DWfDKe61U"
      },
      "outputs": [],
      "source": [
        "model_path = \"/content/drive/MyDrive/Coding/trained_models_sequence_2_label/base_model\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'transformers'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m PretrainedConfig\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m List\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m PreTrainedModel\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
          ]
        }
      ],
      "source": [
        "from transformers import PretrainedConfig\n",
        "from typing import List\n",
        "from transformers import PreTrainedModel\n",
        "\"\"\" PyTorch Facies model.\"\"\"\n",
        "from typing import List, Optional, Tuple, Union\n",
        "import torch\n",
        "from torch import nn\n",
        "from transformers import PreTrainedModel\n",
        "import torch.utils.checkpoint\n",
        "from torch.nn import Transformer\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "from transformers.modeling_outputs import (\n",
        "    Seq2SeqModelOutput,\n",
        "    Seq2SeqLMOutput,\n",
        "    BaseModelOutput,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'PretrainedConfig' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mFaciesConfig\u001b[39;00m(PretrainedConfig):\n\u001b[1;32m      2\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m    This is the configuration class to store the configuration of a [`FaciesModel`]. It is used to instantiate a Facies\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m    model according to the specified arguments, defining the model architecture. Instantiating a configuration with the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39m    >>> configuration = model.config\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39m    ```\"\"\"\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     model_type \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfacies_transformer_seq_2_seq\u001b[39m\u001b[39m\"\u001b[39m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'PretrainedConfig' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "class FaciesConfig(PretrainedConfig):\n",
        "    r\"\"\"\n",
        "    This is the configuration class to store the configuration of a [`FaciesModel`]. It is used to instantiate a Facies\n",
        "    model according to the specified arguments, defining the model architecture. Instantiating a configuration with the\n",
        "    defaults will yield a similar configuration to that of the Facies\n",
        "    [facebook/Facies-large](https://huggingface.co/facebook/Facies-large) architecture.\n",
        "    Configuration objects inherit from [`PretrainedConfig`] and can be used to control the model outputs. Read the\n",
        "    documentation from [`PretrainedConfig`] for more information.\n",
        "    Args:\n",
        "        vocab_size (`int`, *optional*, defaults to 50265):\n",
        "            Vocabulary size of the Facies model. Defines the number of different tokens that can be represented by the\n",
        "            `inputs_ids` passed when calling [`FaciesModel`] or [`TFFaciesModel`].\n",
        "        d_model (`int`, *optional*, defaults to 1024):\n",
        "            Dimensionality of the layers and the pooler layer.\n",
        "        encoder_layers (`int`, *optional*, defaults to 12):\n",
        "            Number of encoder layers.\n",
        "        decoder_layers (`int`, *optional*, defaults to 12):\n",
        "            Number of decoder layers.\n",
        "        encoder_attention_heads (`int`, *optional*, defaults to 16):\n",
        "            Number of attention heads for each attention layer in the Transformer encoder.\n",
        "        decoder_attention_heads (`int`, *optional*, defaults to 16):\n",
        "            Number of attention heads for each attention layer in the Transformer decoder.\n",
        "        decoder_ffn_dim (`int`, *optional*, defaults to 4096):\n",
        "            Dimensionality of the \"intermediate\" (often named feed-forward) layer in decoder.\n",
        "        encoder_ffn_dim (`int`, *optional*, defaults to 4096):\n",
        "            Dimensionality of the \"intermediate\" (often named feed-forward) layer in decoder.\n",
        "        activation_function (`str` or `function`, *optional*, defaults to `\"gelu\"`):\n",
        "            The non-linear activation function (function or string) in the encoder and pooler. If string, `\"gelu\"`,\n",
        "            `\"relu\"`, `\"silu\"` and `\"gelu_new\"` are supported.\n",
        "        dropout (`float`, *optional*, defaults to 0.1):\n",
        "            The dropout probability for all fully connected layers in the embeddings, encoder, and pooler.\n",
        "        attention_dropout (`float`, *optional*, defaults to 0.0):\n",
        "            The dropout ratio for the attention probabilities.\n",
        "        activation_dropout (`float`, *optional*, defaults to 0.0):\n",
        "            The dropout ratio for activations inside the fully connected layer.\n",
        "        classifier_dropout (`float`, *optional*, defaults to 0.0):\n",
        "            The dropout ratio for classifier.\n",
        "        max_position_embeddings (`int`, *optional*, defaults to 1024):\n",
        "            The maximum sequence length that this model might ever be used with. Typically set this to something large\n",
        "            just in case (e.g., 512 or 1024 or 2048).\n",
        "        init_std (`float`, *optional*, defaults to 0.02):\n",
        "            The standard deviation of the truncated_normal_initializer for initializing all weight matrices.\n",
        "        encoder_layerdrop (`float`, *optional*, defaults to 0.0):\n",
        "            The LayerDrop probability for the encoder. See the [LayerDrop paper](see https://arxiv.org/abs/1909.11556)\n",
        "            for more details.\n",
        "        decoder_layerdrop (`float`, *optional*, defaults to 0.0):\n",
        "            The LayerDrop probability for the decoder. See the [LayerDrop paper](see https://arxiv.org/abs/1909.11556)\n",
        "            for more details.\n",
        "        scale_embedding (`bool`, *optional*, defaults to `False`):\n",
        "            Scale embeddings by diving by sqrt(d_model).\n",
        "        use_cache (`bool`, *optional*, defaults to `True`):\n",
        "            Whether or not the model should return the last key/values attentions (not used by all models).\n",
        "        num_labels (`int`, *optional*, defaults to 3):\n",
        "            The number of labels to use in [`FaciesForSequenceClassification`].\n",
        "        forced_eos_token_id (`int`, *optional*, defaults to 2):\n",
        "            The id of the token to force as the last generated token when `max_length` is reached. Usually set to\n",
        "            `eos_token_id`.\n",
        "    Example:\n",
        "    ```python\n",
        "    >>> from transformers import FaciesConfig, FaciesModel\n",
        "    >>> # Initializing a Facies facebook/Facies-large style configuration\n",
        "    >>> configuration = FaciesConfig()\n",
        "    >>> # Initializing a model (with random weights) from the facebook/Facies-large style configuration\n",
        "    >>> model = FaciesModel(configuration)\n",
        "    >>> # Accessing the model configuration\n",
        "    >>> configuration = model.config\n",
        "    ```\"\"\"\n",
        "    model_type = \"facies_transformer_seq_2_seq\"\n",
        "    keys_to_ignore_at_inference = [\"past_key_values\"]\n",
        "    attribute_map = {\n",
        "        \"num_attention_heads\": \"encoder_attention_heads\",\n",
        "        \"hidden_size\": \"d_model\",\n",
        "    }\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size=12,\n",
        "        max_position_embeddings=1024,\n",
        "        encoder_layers=12,\n",
        "        encoder_ffn_dim=4096,\n",
        "        encoder_attention_heads=16,\n",
        "        decoder_layers=12,\n",
        "        decoder_ffn_dim=4096,\n",
        "        decoder_attention_heads=16,\n",
        "        encoder_layerdrop=0.0,\n",
        "        decoder_layerdrop=0.0,\n",
        "        activation_function=\"gelu\",\n",
        "        d_model=1024,\n",
        "        d_input=2,\n",
        "        dropout=0.1,\n",
        "        attention_dropout=0.0,\n",
        "        activation_dropout=0.0,\n",
        "        init_std=0.02,\n",
        "        classifier_dropout=0.0,\n",
        "        scale_embedding=False,\n",
        "        use_cache=True,\n",
        "        num_labels=3,\n",
        "        pad_token_id=1,\n",
        "        bos_token_id=0,\n",
        "        eos_token_id=2,\n",
        "        is_encoder_decoder=True,\n",
        "        decoder_start_token_id=2,\n",
        "        forced_eos_token_id=2,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.d_input = d_input\n",
        "        self.max_position_embeddings = max_position_embeddings\n",
        "        self.d_model = d_model\n",
        "        self.encoder_ffn_dim = encoder_ffn_dim\n",
        "        self.encoder_layers = encoder_layers\n",
        "        self.encoder_attention_heads = encoder_attention_heads\n",
        "        self.decoder_ffn_dim = decoder_ffn_dim\n",
        "        self.decoder_layers = decoder_layers\n",
        "        self.decoder_attention_heads = decoder_attention_heads\n",
        "        self.dropout = dropout\n",
        "        self.attention_dropout = attention_dropout\n",
        "        self.activation_dropout = activation_dropout\n",
        "        self.activation_function = activation_function\n",
        "        self.init_std = init_std\n",
        "        self.encoder_layerdrop = encoder_layerdrop\n",
        "        self.decoder_layerdrop = decoder_layerdrop\n",
        "        self.classifier_dropout = classifier_dropout\n",
        "        self.use_cache = use_cache\n",
        "        self.num_hidden_layers = encoder_layers\n",
        "        self.scale_embedding = (\n",
        "            scale_embedding  # scale factor will be sqrt(d_model) if True\n",
        "        )\n",
        "\n",
        "        super().__init__(\n",
        "            num_labels=num_labels,\n",
        "            pad_token_id=pad_token_id,\n",
        "            bos_token_id=bos_token_id,\n",
        "            eos_token_id=eos_token_id,\n",
        "            is_encoder_decoder=is_encoder_decoder,\n",
        "            decoder_start_token_id=decoder_start_token_id,\n",
        "            forced_eos_token_id=forced_eos_token_id,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "        if self.forced_bos_token_id is None and kwargs.get(\n",
        "            \"force_bos_token_to_be_generated\", False\n",
        "        ):\n",
        "            self.forced_bos_token_id = self.bos_token_id\n",
        "            warnings.warn(\n",
        "                f\"Please make sure the config includes `forced_bos_token_id={self.bos_token_id}` in future versions. \"\n",
        "                \"The config can simply be saved and uploaded again to be fixed.\"\n",
        "            )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model: int, dropout: float, maxlen: int = 6400):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        den = torch.exp(-torch.arange(0, d_model, 2) * math.log(10000) / d_model)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, d_model))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\"pos_embedding\", pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding: Tensor):\n",
        "        return self.dropout(\n",
        "            token_embedding + self.pos_embedding[: token_embedding.size(0), :]\n",
        "        )\n",
        "\n",
        "\n",
        "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size: int, d_model):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, tokens: Tensor):\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.d_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def shift_tokens_right(\n",
        "    input_ids: torch.Tensor, pad_token_id: int, decoder_start_token_id: int\n",
        "):\n",
        "    \"\"\"\n",
        "    Shift input ids one token to the right.\n",
        "    \"\"\"\n",
        "    shifted_input_ids = input_ids.new_zeros(input_ids.shape)\n",
        "    shifted_input_ids[:, 1:] = input_ids[:, :-1].clone()\n",
        "    shifted_input_ids[:, 0] = decoder_start_token_id\n",
        "\n",
        "    if pad_token_id is None:\n",
        "        raise ValueError(\"self.model.config.pad_token_id has to be defined.\")\n",
        "    # replace possible -100 values in labels by `pad_token_id`\n",
        "    shifted_input_ids.masked_fill_(shifted_input_ids == -100, pad_token_id)\n",
        "\n",
        "    return shifted_input_ids\n",
        "\n",
        "\n",
        "def generate_square_subsequent_mask(sz):\n",
        "    mask = torch.triu(torch.ones((sz, sz)) == 1).transpose(0, 1)\n",
        "    mask = (\n",
        "        mask.float()\n",
        "        .masked_fill(mask == 0, float(\"-inf\"))\n",
        "        .masked_fill(mask == 1, float(0.0))\n",
        "    )\n",
        "    return mask\n",
        "\n",
        "\n",
        "def create_mask(src, tgt, PAD_IDX=None, DEVICE=None):\n",
        "    src_mask = None\n",
        "    src_padding_mask = None\n",
        "    if src is not None:\n",
        "        src_seq_len = src.shape[1]\n",
        "        src_mask = torch.zeros((src_seq_len, src_seq_len)).type(torch.bool)\n",
        "        src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
        "\n",
        "    if tgt is not None:\n",
        "        tgt_seq_len = tgt.shape[1]\n",
        "\n",
        "        tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
        "\n",
        "        tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
        "\n",
        "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n",
        "\n",
        "\n",
        "class FaciesPretrainedModel(PreTrainedModel):\n",
        "    config_class = FaciesConfig\n",
        "    base_model_prefix = \"model\"\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        std = self.config.init_std\n",
        "        if isinstance(module, nn.Linear):\n",
        "            module.weight.data.normal_(mean=0.0, std=std)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            module.weight.data.normal_(mean=0.0, std=std)\n",
        "            if module.padding_idx is not None:\n",
        "                module.weight.data[module.padding_idx].zero_()\n",
        "\n",
        "    @property\n",
        "    def dummy_inputs(self):\n",
        "        pad_token = self.config.pad_token_id\n",
        "        input_ids = torch.tensor(\n",
        "            [[0, 6, 10, 4, 2], [0, 8, 12, 2, pad_token]], device=self.device\n",
        "        )\n",
        "        dummy_inputs = {\n",
        "            \"attention_mask\": input_ids.ne(pad_token),\n",
        "            \"input_ids\": input_ids,\n",
        "        }\n",
        "        return dummy_inputs\n",
        "\n",
        "class FaciesModelEncoder(FaciesPretrainedModel):\n",
        "    def __init__(self, config: FaciesConfig, model):\n",
        "        super().__init__(config)\n",
        "        self.config = config\n",
        "        padding_idx, vocab_size = config.pad_token_id, config.vocab_size\n",
        "        self.shared = nn.Embedding(vocab_size, config.d_model, padding_idx)\n",
        "\n",
        "        self.model = model.encoder\n",
        "\n",
        "        self.positional_encoding = PositionalEncoding(\n",
        "            config.d_model, dropout=config.dropout\n",
        "        )\n",
        "\n",
        "        self.embedding_input = torch.nn.Linear(config.d_input, config.d_model)\n",
        "\n",
        "        # Initialize weights and apply final processing\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: torch.LongTensor = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        decoder_input_ids: Optional[torch.LongTensor] = None,\n",
        "        decoder_attention_mask: Optional[torch.LongTensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        decoder_head_mask: Optional[torch.Tensor] = None,\n",
        "        cross_attn_head_mask: Optional[torch.Tensor] = None,\n",
        "        encoder_outputs: Optional[List[torch.FloatTensor]] = None,\n",
        "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
        "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        decoder_inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None,\n",
        "    ) -> Union[Tuple, Seq2SeqModelOutput]:\n",
        "\n",
        "        channel_encoding = self.embedding_input(input_ids.transpose(-1, -2))\n",
        "\n",
        "        output_encoder = self.model(\n",
        "            channel_encoding, mask=None, src_key_padding_mask=None\n",
        "        )\n",
        "\n",
        "        return BaseModelOutput(last_hidden_state=output_encoder)\n",
        "\n",
        "class FaciesModel(FaciesPretrainedModel):\n",
        "    def __init__(self, config: FaciesConfig):\n",
        "        super().__init__(config)\n",
        "        padding_idx, vocab_size = config.pad_token_id, config.vocab_size\n",
        "        self.shared = nn.Embedding(vocab_size, config.d_model, padding_idx)\n",
        "        self.model = Transformer(\n",
        "            d_model=config.d_model,\n",
        "            num_encoder_layers=config.encoder_layers,\n",
        "            nhead=config.decoder_attention_heads,\n",
        "            num_decoder_layers=config.decoder_layers,\n",
        "            dim_feedforward=config.encoder_ffn_dim,\n",
        "            dropout=config.dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.encoder = FaciesModelEncoder(config, self.model)\n",
        "\n",
        "        self.decoder = self.model.decoder\n",
        "\n",
        "        self.positional_encoding = PositionalEncoding(\n",
        "            config.d_model, dropout=config.dropout\n",
        "        )\n",
        "        self.decoder_inputs_embeds = TokenEmbedding(vocab_size, config.d_model)\n",
        "\n",
        "        # Initialize weights and apply final processing\n",
        "        self.post_init()\n",
        "\n",
        "    def get_input_embeddings(self):\n",
        "        return self.shared\n",
        "\n",
        "    def set_input_embeddings(self, value):\n",
        "        self.shared = value\n",
        "        self.encoder.embed_tokens = self.shared\n",
        "        self.decoder.embed_tokens = self.decoder_inputs_embed\n",
        "\n",
        "    def get_encoder(self):\n",
        "        return self.encoder\n",
        "\n",
        "    def get_decoder(self):\n",
        "        return self.decoder\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: torch.LongTensor = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        decoder_input_ids: Optional[torch.LongTensor] = None,\n",
        "        decoder_attention_mask: Optional[torch.LongTensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        decoder_head_mask: Optional[torch.Tensor] = None,\n",
        "        cross_attn_head_mask: Optional[torch.Tensor] = None,\n",
        "        encoder_outputs: Optional[List[torch.FloatTensor]] = None,\n",
        "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
        "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        decoder_inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None,\n",
        "    ) -> Union[Tuple, Seq2SeqModelOutput]:\n",
        "\n",
        "        decoder_input_ids = self.positional_encoding(\n",
        "            self.decoder_inputs_embeds(decoder_input_ids)\n",
        "        )\n",
        "\n",
        "        if encoder_outputs is None:\n",
        "            encoder_outputs = self.encoder(\n",
        "                input_ids\n",
        "            )\n",
        "        # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True\n",
        "        elif return_dict and not isinstance(encoder_outputs, BaseModelOutput):\n",
        "            encoder_outputs = BaseModelOutput(\n",
        "                last_hidden_state=encoder_outputs[0]\n",
        "            )\n",
        "\n",
        "        decoder_output = self.decoder(\n",
        "            decoder_input_ids,\n",
        "            encoder_outputs.last_hidden_state,\n",
        "            tgt_mask=decoder_attention_mask,\n",
        "            memory_mask=None,\n",
        "            tgt_key_padding_mask=None,\n",
        "            memory_key_padding_mask=None,\n",
        "        )\n",
        "\n",
        "        decoder_outputs = BaseModelOutput(last_hidden_state=decoder_output)\n",
        "\n",
        "        return Seq2SeqModelOutput(\n",
        "            last_hidden_state=decoder_outputs.last_hidden_state,\n",
        "            encoder_last_hidden_state=encoder_outputs.last_hidden_state,\n",
        "        )\n",
        "\n",
        "\n",
        "class FaciesForConditionalGeneration(FaciesPretrainedModel):\n",
        "    base_model_prefix = \"model\"\n",
        "\n",
        "    def __init__(self, config: FaciesConfig):\n",
        "        super().__init__(config)\n",
        "        self.model = FaciesModel(config)\n",
        "        self.lm_head = nn.Linear(config.d_model, config.vocab_size, bias=False)\n",
        "\n",
        "        # Initialize weights and apply final processing\n",
        "        self.post_init()\n",
        "\n",
        "    def get_encoder(self):\n",
        "        return self.model.get_encoder()\n",
        "\n",
        "    def get_decoder(self):\n",
        "        return self.model.get_decoder()\n",
        "\n",
        "    def get_output_embeddings(self):\n",
        "        return self.lm_head\n",
        "\n",
        "    def set_output_embeddings(self, new_embeddings):\n",
        "        self.lm_head = new_embeddings\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: torch.LongTensor = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        decoder_input_ids: Optional[torch.LongTensor] = None,\n",
        "        decoder_attention_mask: Optional[torch.LongTensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        decoder_head_mask: Optional[torch.Tensor] = None,\n",
        "        cross_attn_head_mask: Optional[torch.Tensor] = None,\n",
        "        encoder_outputs: Optional[List[torch.FloatTensor]] = None,\n",
        "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
        "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        decoder_inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        labels: Optional[torch.LongTensor] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None,\n",
        "    ) -> Union[Tuple, Seq2SeqLMOutput]:\n",
        "        r\"\"\"\n",
        "        labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
        "            Labels for computing the masked language modeling loss. Indices should either be in `[0, ...,\n",
        "            config.vocab_size]` or -100 (see `input_ids` docstring). Tokens with indices set to `-100` are ignored\n",
        "            (masked), the loss is only computed for the tokens with labels in `[0, ..., config.vocab_size]`.\n",
        "        Returns:\n",
        "        \"\"\"\n",
        "        return_dict = (\n",
        "            return_dict if return_dict is not None else self.config.use_return_dict\n",
        "        )\n",
        "\n",
        "        if labels is not None:\n",
        "            if decoder_input_ids is None and decoder_inputs_embeds is None:\n",
        "                decoder_input_ids = shift_tokens_right(\n",
        "                    labels, self.config.pad_token_id, self.config.decoder_start_token_id\n",
        "                )\n",
        "\n",
        "        (\n",
        "            head_mask,\n",
        "            decoder_attention_mask,\n",
        "            attention_mask,\n",
        "            decoder_head_mask,\n",
        "        ) = create_mask(\n",
        "            input_ids,\n",
        "            decoder_input_ids,\n",
        "            PAD_IDX=self.config.pad_token_id,\n",
        "            DEVICE=decoder_input_ids.device,\n",
        "        )\n",
        "\n",
        "        outputs = self.model(\n",
        "            input_ids=input_ids,\n",
        "            decoder_input_ids=decoder_input_ids,\n",
        "            attention_mask=None,\n",
        "            decoder_attention_mask=decoder_attention_mask.to(device=decoder_input_ids.device),\n",
        "            decoder_head_mask=None,\n",
        "            encoder_outputs=encoder_outputs,\n",
        "        )\n",
        "\n",
        "        lm_logits = self.lm_head(outputs[0])\n",
        "\n",
        "        masked_lm_loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = CrossEntropyLoss()\n",
        "            masked_lm_loss = loss_fct(\n",
        "                lm_logits.view(-1, self.config.vocab_size), labels.view(-1)\n",
        "            )\n",
        "\n",
        "        if not return_dict:\n",
        "            output = (lm_logits,) + outputs[1:]\n",
        "            return (\n",
        "                ((masked_lm_loss,) + output) if masked_lm_loss is not None else output\n",
        "            )\n",
        "\n",
        "        return Seq2SeqLMOutput(loss=masked_lm_loss, logits=lm_logits)\n",
        "\n",
        "    def prepare_inputs_for_generation(\n",
        "        self,\n",
        "        decoder_input_ids,\n",
        "        past=None,\n",
        "        attention_mask=None,\n",
        "        head_mask=None,\n",
        "        decoder_head_mask=None,\n",
        "        cross_attn_head_mask=None,\n",
        "        use_cache=None,\n",
        "        encoder_outputs=None,\n",
        "        **kwargs\n",
        "    ):\n",
        "        # cut decoder_input_ids if past is used\n",
        "        if past is not None:\n",
        "            decoder_input_ids = decoder_input_ids[:, -1:]\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": None,  # encoder_outputs is defined. input_ids not needed\n",
        "            \"encoder_outputs\": encoder_outputs,\n",
        "            \"past_key_values\": past,\n",
        "            \"decoder_input_ids\": decoder_input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"head_mask\": head_mask,\n",
        "            \"decoder_head_mask\": decoder_head_mask,\n",
        "            \"cross_attn_head_mask\": cross_attn_head_mask,\n",
        "            \"use_cache\": use_cache,  # change this to avoid caching (presumably for debugging)\n",
        "        }\n",
        "\n",
        "    def prepare_decoder_input_ids_from_labels(self, labels: torch.Tensor):\n",
        "        return shift_tokens_right(\n",
        "            labels, self.config.pad_token_id, self.config.decoder_start_token_id\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer, logging\n",
        "from hf_sequence_to_sequence.model import FaciesForConditionalGeneration\n",
        "from hf_sequence_to_sequence.configuration import FaciesConfig\n",
        "import torchmetrics\n",
        "import math\n",
        "import time\n",
        "from torch import nn, optim\n",
        "from torch.optim import Adam\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from dataset.dataset import WellsDataset\n",
        "from torch.utils.data import random_split\n",
        "from utils import epoch_time\n",
        "from conf import DEVICE\n",
        "from conf import (\n",
        "    batch_size,\n",
        "    max_len,\n",
        "    d_model,\n",
        "    n_layers,\n",
        "    n_heads,\n",
        "    ffn_hidden,\n",
        "    drop_prob,\n",
        "    model_path,\n",
        ")\n",
        "from conf import (\n",
        "    init_lr,\n",
        "    factor,\n",
        "    adam_eps,\n",
        "    patience,\n",
        "    warmup,\n",
        "    epoch,\n",
        "    clip,\n",
        "    weight_decay,\n",
        "    inf,\n",
        ")\n",
        "from conf import WIRELINE_LOGS_HEADER, LABEL_COLUMN_HEADER, SEQUENCE_LEN, TRAINING_RATIO\n",
        "from typing import List"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for src_sample, tgt_sample in batch:\n",
        "        tgt_batch.append(tgt_sample)\n",
        "        src_batch.append(src_sample)\n",
        "\n",
        "    src_batch = torch.stack(src_batch)\n",
        "    tgt_batch = torch.stack(tgt_batch)\n",
        "\n",
        "    model_input = {\"input_ids\": src_batch, \"labels\": tgt_batch}\n",
        "    return model_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.9.13 64-bit' requires ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/usr/local/bin/python3.9 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "\n",
        "# GPU device setting\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_path = \"saved_models/model_\"\n",
        "\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
        "special_symbols = [\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"]\n",
        "\n",
        "SEQUENCE_LEN = 20\n",
        "TRAINING_RATIO = 0.90\n",
        "WIRELINE_LOGS_HEADER = [\"DEPTH_MD\", \"GR\", \"NPHI\"]\n",
        "LABEL_COLUMN_HEADER = [\"FORCE_2020_LITHOFACIES_LITHOLOGY\"]\n",
        "\n",
        "train_dataset = WellsDataset(\n",
        "    dataset_type=\"train\",\n",
        "    sequence_len=SEQUENCE_LEN,\n",
        "    model_type=\"seq2seq\",\n",
        "    feature_columns=WIRELINE_LOGS_HEADER,\n",
        "    label_columns=LABEL_COLUMN_HEADER,\n",
        ")\n",
        "\n",
        "DATA_LEN = train_dataset.train_len\n",
        "d_input = train_dataset.input_len\n",
        "d_output = train_dataset.output_len\n",
        "d_channel = train_dataset.channel_len\n",
        "tgt_vocab_size = train_dataset.output_len + len(train_dataset.special_symbols)\n",
        "TRAIN_DATA_LEN = int(DATA_LEN * TRAINING_RATIO)\n",
        "\n",
        "facies_config = {\n",
        "    \"vocab_size\": tgt_vocab_size,\n",
        "    \"max_position_embeddings\": 1024,\n",
        "    \"encoder_layers\": 4,\n",
        "    \"encoder_ffn_dim\": 1024,\n",
        "    \"encoder_attention_heads\": 4,\n",
        "    \"decoder_layers\": 4,\n",
        "    \"decoder_ffn_dim\": 1024,\n",
        "    \"decoder_attention_heads\": 4,\n",
        "    \"encoder_layerdrop\": 0.0,\n",
        "    \"decoder_layerdrop\": 0.0,\n",
        "    \"activation_function\": \"relu\",\n",
        "    \"d_model\": 512,\n",
        "    \"d_input\": d_input,\n",
        "    \"dropout\": 0.1,\n",
        "    \"attention_dropout\": 0.0,\n",
        "    \"activation_dropout\": 0.0,\n",
        "    \"init_std\": 0.02,\n",
        "    \"classifier_dropout\": 0.0,\n",
        "    \"scale_embedding\": False,\n",
        "    \"use_cache\": False,\n",
        "    \"num_labels\": tgt_vocab_size,\n",
        "    \"pad_token_id\": PAD_IDX,\n",
        "    \"bos_token_id\": BOS_IDX,\n",
        "    \"eos_token_id\": EOS_IDX,\n",
        "    \"is_encoder_decoder\": True,\n",
        "    \"decoder_start_token_id\": 2,\n",
        "    \"forced_eos_token_id\": EOS_IDX,\n",
        "}\n",
        "\n",
        "train_data, validation_data = random_split(\n",
        "    train_dataset, lengths=[TRAIN_DATA_LEN, DATA_LEN - TRAIN_DATA_LEN]\n",
        ")\n",
        "\n",
        "facies_transformer_config = FaciesConfig(**facies_config)\n",
        "facies_transformer_config.save_pretrained(\"facies-transformer-config\")\n",
        "facies_transformer_config = FaciesConfig.from_pretrained(\"facies-transformer-config\")\n",
        "\n",
        "facies_transformer = FaciesForConditionalGeneration(facies_transformer_config)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"saved_models/\",\n",
        "    per_device_train_batch_size=640,\n",
        "    per_device_eval_batch_size=640,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    num_train_epochs=4,\n",
        ")\n",
        "trainer = Trainer(\n",
        "    model=facies_transformer,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=validation_data,\n",
        "    data_collator=collate_fn,\n",
        "    args=training_args,\n",
        ")\n",
        "result = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.9.13 64-bit' requires ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/usr/local/bin/python3.9 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "\n",
        "test_dataset = WellsDataset(\n",
        "    dataset_type=\"test\",\n",
        "    sequence_len=SEQUENCE_LEN,\n",
        "    model_type=\"seq2seq\",\n",
        "    feature_columns=WIRELINE_LOGS_HEADER,\n",
        "    label_columns=LABEL_COLUMN_HEADER,\n",
        "    scaler=train_dataset.scaler,\n",
        "    output_len=train_dataset.output_len,\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "\n",
        "# Loop for generating the output of a sequence for all the data in the test dataloader using model.generate\n",
        "for i, batch in enumerate(test_loader):\n",
        "    input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "    outputs = facies_transformer.generate(\n",
        "        input_ids=input_ids,\n",
        "        num_beams=8,\n",
        "        num_return_sequences=1,\n",
        "        max_new_tokens=SEQUENCE_LEN+1\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
